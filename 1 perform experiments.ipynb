{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16678a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac63dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import json\n",
    "import numpy as np\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd404ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.llms import HuggingFaceTextGenInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6924c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    \"\"\"Encoder to ensure numpy objects are serialised to JSON correctly\"\"\"\n",
    "    \n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import HUGGINGFACE_API_KEY\n",
    "from api_key import OPENAI_API_KEY\n",
    "from api_key import RUNPOD_API_KEY\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACE_API_KEY\n",
    "os.environ['OPENAI_API_KEY']=OPENAI_API_KEY\n",
    "os.environ[\"RUNPOD_AI_API_KEY\"] = RUNPOD_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6120a-22bf-4f0a-90c9-cb1131541883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import runpod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_utils import perform_message_inference, tidy_responses, STANDARD_RESPONSES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebd782-17c0-41a6-ac54-f18e427bb8a4",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13deb812-49b3-4cee-ba9b-31142ee663d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cleaner = partial(tidy_responses, keywords=STANDARD_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0334e-7085-4606-adbc-a219c8de9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_cleaner = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmks = pd.read_csv('clean_bmk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d20e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSVP(Enum):\n",
    "    Attend = 1\n",
    "    Not_attend = 2\n",
    "    Possibly_attend = 3\n",
    "    Other = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065eac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_rsvp_value(text):\n",
    "\n",
    "    if text is None:\n",
    "        return RSVP.Other.value\n",
    "    \n",
    "    tidy_val = text.replace(' ','_')\n",
    "    return RSVP[tidy_val].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd2a2d-e112-4840-8b87-284bab03e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_numeric_value(text):\n",
    "\n",
    "    if text is None:\n",
    "        return RSVP.Other.value\n",
    "\n",
    "    if text.strip() == '1':\n",
    "        return RSVP.Attend.value\n",
    "    elif text.strip() == '2':\n",
    "        return RSVP.Not_attend.value\n",
    "    elif text.strip() == '3':\n",
    "        return RSVP.Possibly_attend.value\n",
    "    else:\n",
    "        return RSVP.Other.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmks['review_class'] = bmks['review'].apply(map_rsvp_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e01f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmks.review.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc41629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_metrics(true, pred, class_labels):\n",
    "    \"\"\"https://programtalk.com/python-more-examples/sklearn.metrics.precision_recall_fscore_support/?ipage=4&utm_content=cmp-true\"\"\"\n",
    "\n",
    "    # Prepare headers\n",
    "    table_three_headers = tuple([\"\", \"Accuracy\", \"Macro-F\"] + sorted(class_labels))\n",
    "    results_headers = (\"Precision\", \"Recall\", \"F-score\", \"Support\")\n",
    "    \n",
    "    results={}\n",
    "\n",
    "    print(\"\\nResults on testing set\")\n",
    "\n",
    "    test_accuracy = accuracy_score(true, pred)\n",
    "    print(\"\\nAccuracy =\", test_accuracy)\n",
    "    \n",
    "    results['accuracy']=test_accuracy\n",
    "\n",
    "    print(\"\\nMacro-average:\")\n",
    "    macroavg_prfs = precision_recall_fscore_support(true, pred, average='macro')\n",
    "    for lab, val in zip(results_headers, macroavg_prfs):\n",
    "        if val is not None:\n",
    "            print(\"%-12s%-12.3f\" % (lab, val))\n",
    "        else:\n",
    "            print(\"%-12s%-12s\" % (lab, \"--\"))\n",
    "            \n",
    "    results['macro']=macroavg_prfs\n",
    "\n",
    "    print(\"\\nPer-class:\")\n",
    "    perclass_prfs = precision_recall_fscore_support(true, pred)\n",
    "    print(\"%-12s%-12s%-12s%-12s%-12s\" % tuple([\"\"] + sorted(class_labels)))\n",
    "    for lab, vals in zip(results_headers, perclass_prfs):\n",
    "        if lab == \"Support\":\n",
    "            print(\"%-12s%-12i%-12i%-12i%-12i\" % (lab, vals[0], vals[1], vals[2], vals[3]))\n",
    "        else:\n",
    "            print(\"%-12s%-12.3f%-12.3f%-12.3f%-12.3f\" % (lab, vals[0], vals[1], vals[2], vals[3]))\n",
    "\n",
    "    per_metric={}\n",
    "    for lab, vals in zip(results_headers, perclass_prfs):\n",
    "        per_class={}\n",
    "        for i,cls in enumerate(class_labels):\n",
    "            per_class[cls]=vals[i]\n",
    "        \n",
    "        per_metric[lab]=per_class\n",
    "    \n",
    "    results['per_class']=per_metric\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b8109",
   "metadata": {},
   "source": [
    "### database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22deb0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from database_models import  Experiments_Base, Prompts, Models, Experiments\n",
    "from sqlalchemy import select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_utils import get_prompt, add_prompt, get_prompt_names\n",
    "from db_utils import get_model, add_model\n",
    "from db_utils import add_experiment, get_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c28657",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///experiments.db', json_serializer=lambda obj: json.dumps(obj, cls=NpEncoder))\n",
    "Experiments_Base.metadata.create_all(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9028f84-1e32-40f4-b655-2290a4414d04",
   "metadata": {},
   "source": [
    "prompts=[\n",
    "    {'short_name':'alpaca style',\n",
    "    'prompt_text':\"\"\"### Instruction:\n",
    "From the supplied message determine if the sender intends to attend the event. Reply with one of these four responses: Attend, Not attend, Possibly attend or Other.\n",
    "\n",
    "### Input:\n",
    "{message}\n",
    "\n",
    "### Response:\n",
    "\"\"\"},\n",
    "    {'short_name':'alpaca succint',\n",
    "    'prompt_text':\"\"\"### Instruction:\n",
    "From the supplied message determine if the sender intends to attend the event. Reply succintly with only one of these four responses: Attend, Not attend, Possibly attend or Other.\n",
    "\n",
    "### Input:\n",
    "{message}\n",
    "\n",
    "### Response:\n",
    "\"\"\"},\n",
    "{'short_name':'example',\n",
    "    'prompt_text':\"\"\"Given an RSVP message determine if the sender will attend?\n",
    "Examples:\n",
    "Alice: I will come - Attend\n",
    "Bob: I will not come - Not Attend\n",
    "Charlie: I may come - Possibly Attend\n",
    "Diana: Where is it? - Other\n",
    "\n",
    "Message:\n",
    "{message} -\n",
    "\n",
    "\"\"\"},\n",
    "{'short_name':'original bmk',\n",
    "    'prompt_text':\"\"\"From the supplied message determine if the sender intends to attend the event -\n",
    "    reply with one of these four responses -  \n",
    "    Attend, Not attend, Possibly attend or Other.\n",
    "    Supplied message: {message}\"\"\"},\n",
    "{'short_name':'numeric succint',\n",
    "    'prompt_text':\"\"\"### Instruction:\n",
    "From the supplied message determine if the sender intends to attend the event. \n",
    "Reply succintly with only one of these four numeric responses: \n",
    "Reply 1 if they will Attend\n",
    "Reply 2 if they will Not attend\n",
    "Reply 3 if they will Possibly attend\n",
    "Reply 4 for all other outcomes.\n",
    "\n",
    "### Input:\n",
    "{message}\n",
    "\n",
    "### Response:\"\"\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6b53a27",
   "metadata": {},
   "source": [
    "for prompt in prompts:\n",
    "    add_prompt(session, prompt['short_name'],prompt['prompt_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prompt_names(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51391d17",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc18793-a51d-4beb-bf4c-2126fc115945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmarking(exp, llm_link=None):\n",
    "\n",
    "    assert type(exp)==dict\n",
    "\n",
    "    print(exp['model'])\n",
    "    \n",
    "    model_obj = get_model(session,exp['model'])\n",
    "\n",
    "    platform_type = exp['platform']\n",
    "\n",
    "    if platform_type == 'openai':\n",
    "        llm=OpenAI(temperature=0.5)\n",
    "    elif platform_type == 'chat_openai':\n",
    "        llm=ChatOpenAI(model='gpt-4',temperature=0.5)\n",
    "    elif platform_type == 'hf_hub':\n",
    "        repo_id = exp['model']\n",
    "        llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_length\": 128})\n",
    "    elif platform_type == 'run_pod':\n",
    "        llm = llm_link\n",
    "    \n",
    "    for prompt_data in exp['prompts']:\n",
    "        short_name = prompt_data[\"short_name\"]\n",
    "        cleaner = prompt_data['cleaner']\n",
    "        mapper = prompt_data['mapper']\n",
    "                \n",
    "        print(f'prompt name: {short_name}')\n",
    "        \n",
    "        prompt_obj = get_prompt(session,short_name)\n",
    "\n",
    "        experiment_check = get_experiment(session,model_obj.id,prompt_obj.id)\n",
    "        \n",
    "        if experiment_check is not None:\n",
    "            acc = experiment_check.results['accuracy']\n",
    "            print(f'Experiment previously performed with accuracy {acc}')\n",
    "\n",
    "        else:\n",
    "            preds=[]\n",
    "            for tm in tqdm(bmks['message'].to_list()):\n",
    "                # cycle messages\n",
    "                raw = perform_message_inference(llm,prompt_obj.prompt_text,tm)\n",
    "\n",
    "                print(f'raw: {raw}')\n",
    "                clean = cleaner(raw)\n",
    "                print(f'clean: {clean}')\n",
    "                mapped = mapper(clean)\n",
    "                print(f'mapped: {mapped}')\n",
    "                \n",
    "                preds.append(mapped)\n",
    "\n",
    "            metrics = prepare_metrics(bmks.review_class.to_list(), preds,[1,2,3,4])\n",
    "\n",
    "            add_experiment(session,model_obj.id,prompt_obj.id,'bmks_81',metrics)\n",
    "\n",
    "    return model_obj.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9037624a-c57d-47eb-bb27-b9001a5af9cc",
   "metadata": {},
   "source": [
    "### Ready External LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d6bd21-6527-4144-9efb-b98de2d3f610",
   "metadata": {},
   "source": [
    "#### prepare runpod and connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c30d0-1f35-45ce-9af8-2e8d9a4dc793",
   "metadata": {},
   "outputs": [],
   "source": [
    "runpod.api_key = os.getenv(\"RUNPOD_AI_API_KEY\", \"your_runpod_api_key\")\n",
    "\n",
    "if runpod.api_key == \"your_runpod_api_key\":\n",
    "    print(\"It appears that you don't have a RunPod API key\")\n",
    "\n",
    "    raise AssertionError(\"Missing RunPod API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90f467-6b18-412e-9c9f-d0bcd4a4c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller model parameters\n",
    "gpu_count = 1\n",
    "gpu_type=\"NVIDIA RTX A6000\"\n",
    "# repo_id = 'meta-llama/Llama-2-7b-chat-hf' # ~ 24GB?\n",
    "repo_id = 'meta-llama/Llama-2-13b-chat-hf' # ~ 26GB?\n",
    "# repo_id = 'tiiuae/falcon-7b-instruct' # ~ 24GB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e25ed4-efac-4fb9-aa20-3870ab526d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger model parameters\n",
    "# gpu_count = 2\n",
    "# gpu_type = \"NVIDIA A100 80GB PCIe\"\n",
    "# repo_id = 'meta-llama/Llama-2-70b-chat-hf' # ~ 140GB?\n",
    "# repo_id = 'tiiuae/falcon-40b-instruct' # ~ 140GB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835962d-cd0b-428c-a368-c6e53c599927",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8a9a1-f9a5-4439-9e53-0fa0f306b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = get_model(session, repo_id)\n",
    "if model_obj is None:\n",
    "    add_model(session,repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00182ee-9ed0-41c3-9006-4f873f0f5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod = runpod.create_pod(\n",
    "    name=\"Party Bot Benchmarking\",\n",
    "    image_name=\"ghcr.io/huggingface/text-generation-inference\",\n",
    "    gpu_type_id=gpu_type, \n",
    "    cloud_type=\"COMMUNITY\",\n",
    "    docker_args=f\"--model-id {repo_id} --num-shard {gpu_count}\",\n",
    "    gpu_count=gpu_count,\n",
    "    volume_in_gb=195,\n",
    "    container_disk_in_gb=5,\n",
    "    ports=\"80/http\",\n",
    "    volume_mount_path=\"/data\",\n",
    "    env={'HUGGING_FACE_HUB_TOKEN':HUGGINGFACE_API_KEY, 'MAX_JOBS':4, 'shm-size':'1g'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6af49-a40d-4d83-a8ed-2c293c281599",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33873062-d221-4720-9f7c-38552b27293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_server_url = f'https://{pod[\"id\"]}-80.proxy.runpod.net'\n",
    "llm = HuggingFaceTextGenInference(\n",
    "    inference_server_url=inference_server_url,\n",
    "    max_new_tokens=100,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    typical_p=0.95,\n",
    "    temperature=0.5,\n",
    "    repetition_penalty=1.03,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052afedc-a3e5-4475-ab53-bd7959b864be",
   "metadata": {},
   "source": [
    "#### perform run_pod benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9075f1-cc0c-45d0-9585-0501056aead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_card={'model':repo_id,'platform':'run_pod',\n",
    "           'prompts':[\n",
    "               {'short_name': 'alpaca style','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'alpaca succint','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'example','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'original bmk','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'numeric succint','mapper':map_numeric_value, 'cleaner':blank_cleaner},\n",
    "                ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33cf81f-2e80-49e3-bb73-d4a9c6ba559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d60d9c-0dff-44bc-a756-0e0b2e6e8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = get_model(session, experiment_card['model'])\n",
    "if model_obj is None:\n",
    "    add_model(session, experiment_card['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d476b7-5555-4771-b4b9-252419f5763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = run_benchmarking(experiment_card, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f9221-0cf4-451f-b936-1172a2bbcb8e",
   "metadata": {},
   "source": [
    "#### close down run_pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7ac37a-5e55-48c5-9024-45c3204e7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runpod.stop_pod(pod[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa84855f-e403-4f58-9cc4-37e58090bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "runpod.terminate_pod(pod[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652b9a3-3a3a-4e8d-ae11-038421f332ea",
   "metadata": {},
   "source": [
    "### run against API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977d305-48cc-44cb-a73e-d7aafe1798d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_card={'model':'google/flan-t5-xxl','platform':'hf_hub',\n",
    "          'prompts':[\n",
    "               {'short_name': 'alpaca style','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'alpaca succint','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'example','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'original bmk','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'numeric succint','mapper':map_numeric_value, 'cleaner':blank_cleaner},\n",
    "                ]}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f56ee86d-cca4-424d-8725-f33542a24940",
   "metadata": {},
   "source": [
    "experiment_card={'model':'openai','platform':'openai',\n",
    "           'prompts':[\n",
    "               {'short_name': 'alpaca style','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'alpaca succint','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'example','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'original bmk','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'numeric succint','mapper':map_numeric_value, 'cleaner':blank_cleaner},\n",
    "                ]}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ca8fa8b-1bcf-4553-a1e2-46e827fb2f0a",
   "metadata": {},
   "source": [
    "experiment_card={'model':'openai-gpt4','platform':'chat_openai',\n",
    "           'prompts':[\n",
    "               {'short_name': 'alpaca style','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'alpaca succint','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'example','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'original bmk','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'numeric succint','mapper':map_numeric_value, 'cleaner':blank_cleaner},\n",
    "                ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4c877-90f4-45a2-bb71-ec96eed581bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = get_model(session, experiment_card['model'])\n",
    "if model_obj is None:\n",
    "    add_model(session, experiment_card['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9aed65-4cb8-42b0-b548-dabf4caed10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = run_benchmarking(experiment_card, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee3f60-ba08-4f03-910c-698df2239d00",
   "metadata": {},
   "source": [
    "### Local model running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff54bfc-41e3-4bd2-a55f-5edabb1787bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c566c1-ef70-4657-8dea-71451fa1e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"databricks/dolly-v2-3b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f15757-dae4-4c1c-bb6e-5da3d93d8b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text = pipeline(model=repo_id, torch_dtype=torch.bfloat16,\n",
    "                         trust_remote_code=True, device_map=\"auto\", return_full_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e21adf-27ca-4156-b59f-01b05fad477d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = get_model(session, repo_id)\n",
    "if model_obj is None:\n",
    "    add_model(session,repo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f432be-4e54-4b3d-8012-91711aeeeda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_card={'model':repo_id,'platform':'run_pod',\n",
    "           'prompts':[\n",
    "               {'short_name': 'alpaca style','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'alpaca succint','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'example','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'original bmk','mapper':map_rsvp_value, 'cleaner':word_cleaner},\n",
    "               {'short_name': 'numeric succint','mapper':map_numeric_value, 'cleaner':blank_cleaner},\n",
    "                ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8561d17-b824-4d26-9312-7490aeec370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline=generate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d8f41-fe80-4a65-9c73-0dc74120e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = run_benchmarking(experiment_card, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9788156-fa40-41df-8ba1-38cbfdf0036b",
   "metadata": {},
   "source": [
    "### Review results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a3dfd9-cf8f-4d04-bdca-62e7b054633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8822a4c-faca-4098-af91-cd73a83f1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = session.connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8eec6-9f84-4b0d-9d75-58677611f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_sql(sql=\"\"\"select short_name, model_name, results\n",
    "from experiments\n",
    "left join models on experiments.model_id = models.id\n",
    "left join prompts on experiments.prompt_id = prompts.id\n",
    "order by model_name\n",
    "\"\"\", con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7af51-f826-4d59-a6ea-f46a5471c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c56eb-631c-4031-9a61-26f697ec5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = results_df['results'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7cd78-e0a4-4797-95e7-c4ef4131cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results =[]\n",
    "for k,v in results_dict.items():\n",
    "    # print(k)\n",
    "    js = json.loads(v)\n",
    "    flat_js = json_normalize(js,sep='_')\n",
    "    flat_js['idx']=k\n",
    "    all_results.append(flat_js)\n",
    "\n",
    "all_results_df = pd.concat(all_results)\n",
    "all_results_df.set_index('idx',inplace=True)\n",
    "all_results_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5dd25-2aad-467b-95ec-f1db2de67288",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_join = results_df.join(all_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833173f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677becc-5b99-45af-939a-0f2ab224f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_join.to_csv('experiment_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de636c4-5260-43ca-bab1-b54336c8c310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
